# TO-DOS

## ✅ COMPLETED: Fix Extraction Refinement Prompt - Allow Logic Changes - 2025-11-18 22:33

- **DONE: Removed misleading constraint from extraction refinement prompt** - Removed "Keep the same SMT-LIB logic" from refinement prompt which could prevent fixing incorrect or incomplete logic. **Implementation:** Rewrote refinement prompt in `src/infrastructure/llm/client.py:215-230` to explicitly allow and encourage logic changes. New prompt includes 6-step checklist: (1) review if logic captures ALL constraints, (2) check for missing constraints, (3) verify variable declarations, (4) fix logical errors, (5) add detailed comments, (6) include variable context. Emphasizes that LLM should change logic AND/OR annotations as needed. **Rationale:** Degradation measures embedding similarity - if logic is wrong, comments won't fix it. Previous prompt was counterproductive by restricting changes to annotations only.

## ✅ COMPLETED: Conversation-Based Refinement for Extraction - 2025-11-18 22:25

- **DONE: Implemented refinement logic for extraction retries** - Extraction now uses conversation-based refinement matching formalization pattern. **Implementation:** Added previous_attempt and previous_degradation parameters to LLMProvider.extract_to_smtlib protocol (`src/domain/protocols.py:56-77`). Updated AnthropicClient.extract_to_smtlib (`src/infrastructure/llm/client.py:162-248`) to build 3-message conversation on retry: initial prompt → previous SMT code → refinement feedback with degradation score and guidance. Updated extraction.py retry loop (`src/domain/steps/extraction.py:85-138`) to track and pass previous attempts. Temperature stays 0.0 for deterministic code generation. **Benefits:** Better convergence through iterative refinement vs simple regeneration, maintains context across retries, explicit feedback guides LLM to reduce information loss.

## ✅ COMPLETED: Use Exact 5-Phase SMT Prompt - 2025-11-18 22:12

- **DONE: Replaced EXTRACTION_PROMPT with exact 5-phase prompt** - The exact battle-tested 5-phase prompt from convert_to_smtlib function has been implemented verbatim in `src/infrastructure/llm/prompts.py:18-98`. The prompt enforces: Phase 1 (problem comprehension with data inventory), Phase 2 (domain modeling with ground truth vs unknowns, assert-and-test pattern for YES/NO), Phase 3 (logic selection decision tree), Phase 4 (SMT-LIB encoding with uninterpreted function linking constraints), Phase 5 (self-verification checklist). Only change made: replaced `{enhanced_text}` placeholder with `{formal_text}` to match our variable naming. Function `get_extraction_prompt()` updated to use new prompt (detail_level parameter deprecated but kept for API compatibility).