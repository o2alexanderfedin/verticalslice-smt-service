# TO-DOS

## Enforce Zero Temperature for Extraction - 2025-11-18 22:19

- **Ensure extraction temperature stays at 0.0 with no variations** - Extraction must use deterministic temperature (0.0) for all attempts with no increases or changes. **Problem:** Need to verify and document that extraction maintains temperature=0 consistently, similar to formalization. Currently hardcoded to 0.0 in `src/infrastructure/llm/client.py:196`, but should verify this is enforced and cannot be accidentally changed via config or retry logic. **Files:** `src/infrastructure/llm/client.py:162-212` (extract_to_smtlib method), `src/domain/steps/extraction.py:86-130` (retry loop), `src/shared/config.py:105-133` (extraction settings). **Solution:** Verify temperature is hardcoded to 0.0 in extract_to_smtlib method, ensure no config setting can override it, and confirm retry loop doesn't modify temperature (unlike formalization which had temp_step). Add documentation/comment emphasizing temperature must remain 0.0 for deterministic code generation.

## ✅ COMPLETED: Conversation-Based Refinement for Extraction - 2025-11-18 22:25

- **DONE: Implemented refinement logic for extraction retries** - Extraction now uses conversation-based refinement matching formalization pattern. **Implementation:** Added previous_attempt and previous_degradation parameters to LLMProvider.extract_to_smtlib protocol (`src/domain/protocols.py:56-77`). Updated AnthropicClient.extract_to_smtlib (`src/infrastructure/llm/client.py:162-248`) to build 3-message conversation on retry: initial prompt → previous SMT code → refinement feedback with degradation score and guidance. Updated extraction.py retry loop (`src/domain/steps/extraction.py:85-138`) to track and pass previous attempts. Temperature stays 0.0 for deterministic code generation. **Benefits:** Better convergence through iterative refinement vs simple regeneration, maintains context across retries, explicit feedback guides LLM to reduce information loss.

## ✅ COMPLETED: Use Exact 5-Phase SMT Prompt - 2025-11-18 22:12

- **DONE: Replaced EXTRACTION_PROMPT with exact 5-phase prompt** - The exact battle-tested 5-phase prompt from convert_to_smtlib function has been implemented verbatim in `src/infrastructure/llm/prompts.py:18-98`. The prompt enforces: Phase 1 (problem comprehension with data inventory), Phase 2 (domain modeling with ground truth vs unknowns, assert-and-test pattern for YES/NO), Phase 3 (logic selection decision tree), Phase 4 (SMT-LIB encoding with uninterpreted function linking constraints), Phase 5 (self-verification checklist). Only change made: replaced `{enhanced_text}` placeholder with `{formal_text}` to match our variable naming. Function `get_extraction_prompt()` updated to use new prompt (detail_level parameter deprecated but kept for API compatibility).