# TO-DOS

## Implement Conversation-Based Refinement for Extraction - 2025-11-18 22:25

- **Add refinement logic to extraction retries matching formalization pattern** - Extraction retries should use conversation-based refinement instead of just regenerating with higher detail_level. **Problem:** Currently extraction.py simply retries with increasing detail_level (0.5 → 0.6 → 0.7...), but doesn't use the previous attempt as context for refinement. Formalization successfully uses multi-turn conversation (previous_attempt + previous_similarity) to refine iteratively. Extraction should follow the same pattern for better convergence. **Files:** `src/domain/steps/extraction.py:86-147` (retry loop needs previous_attempt/previous_degradation tracking), `src/domain/protocols.py:56-74` (LLMProvider.extract_to_smtlib needs previous_attempt parameter), `src/infrastructure/llm/client.py:162-212` (AnthropicClient.extract_to_smtlib needs conversation building like formalize method). **Solution:** Add optional previous_attempt and previous_degradation parameters to extract_to_smtlib protocol and implementation. Build 3-message conversation on retry: initial prompt → previous SMT code → refinement feedback with degradation score. Track previous_attempt and previous_degradation in extraction.py retry loop, similar to formalization.py:112-171.

## Enforce Zero Temperature for Extraction - 2025-11-18 22:19

- **Ensure extraction temperature stays at 0.0 with no variations** - Extraction must use deterministic temperature (0.0) for all attempts with no increases or changes. **Problem:** Need to verify and document that extraction maintains temperature=0 consistently, similar to formalization. Currently hardcoded to 0.0 in `src/infrastructure/llm/client.py:196`, but should verify this is enforced and cannot be accidentally changed via config or retry logic. **Files:** `src/infrastructure/llm/client.py:162-212` (extract_to_smtlib method), `src/domain/steps/extraction.py:86-130` (retry loop), `src/shared/config.py:105-133` (extraction settings). **Solution:** Verify temperature is hardcoded to 0.0 in extract_to_smtlib method, ensure no config setting can override it, and confirm retry loop doesn't modify temperature (unlike formalization which had temp_step). Add documentation/comment emphasizing temperature must remain 0.0 for deterministic code generation.

## ✅ COMPLETED: Use Exact 5-Phase SMT Prompt - 2025-11-18 22:12

- **DONE: Replaced EXTRACTION_PROMPT with exact 5-phase prompt** - The exact battle-tested 5-phase prompt from convert_to_smtlib function has been implemented verbatim in `src/infrastructure/llm/prompts.py:18-98`. The prompt enforces: Phase 1 (problem comprehension with data inventory), Phase 2 (domain modeling with ground truth vs unknowns, assert-and-test pattern for YES/NO), Phase 3 (logic selection decision tree), Phase 4 (SMT-LIB encoding with uninterpreted function linking constraints), Phase 5 (self-verification checklist). Only change made: replaced `{enhanced_text}` placeholder with `{formal_text}` to match our variable naming. Function `get_extraction_prompt()` updated to use new prompt (detail_level parameter deprecated but kept for API compatibility).