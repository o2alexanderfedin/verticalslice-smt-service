# TO-DOS

## Fix Extraction Refinement Prompt - Allow Logic Changes - 2025-11-18 22:33

- **Remove misleading constraint in extraction refinement prompt** - The refinement prompt currently says "Keep the same SMT-LIB logic, but enhance annotations to reduce information loss" which could prevent LLM from fixing incorrect logic. **Problem:** Information degradation is measured by embedding similarity between formal text and SMT-LIB code. If the SMT-LIB logic is wrong or incomplete, adding more comments won't reduce degradation - the logic itself needs to be fixed. The current prompt at `src/infrastructure/llm/client.py:215-225` tells LLM to keep the logic unchanged, which could result in cosmetic fixes (better annotations) instead of substantive fixes (correct logic). This is misleading and counterproductive. **Files:** `src/infrastructure/llm/client.py:215-225` (refinement_prompt in extract_to_smtlib method). **Solution:** Rewrite refinement prompt to allow LLM to revise BOTH logic AND annotations. Remove "Keep the same SMT-LIB logic" constraint. Instead, emphasize: "Review the previous SMT-LIB code and improve it to better match the formal text. You may need to fix the logic, add missing constraints, or enhance annotations - whatever reduces information loss." Focus on correctness and completeness, not just documentation.

## Enforce Zero Temperature for Extraction - 2025-11-18 22:19

- **Ensure extraction temperature stays at 0.0 with no variations** - Extraction must use deterministic temperature (0.0) for all attempts with no increases or changes. **Problem:** Need to verify and document that extraction maintains temperature=0 consistently, similar to formalization. Currently hardcoded to 0.0 in `src/infrastructure/llm/client.py:196`, but should verify this is enforced and cannot be accidentally changed via config or retry logic. **Files:** `src/infrastructure/llm/client.py:162-212` (extract_to_smtlib method), `src/domain/steps/extraction.py:86-130` (retry loop), `src/shared/config.py:105-133` (extraction settings). **Solution:** Verify temperature is hardcoded to 0.0 in extract_to_smtlib method, ensure no config setting can override it, and confirm retry loop doesn't modify temperature (unlike formalization which had temp_step). Add documentation/comment emphasizing temperature must remain 0.0 for deterministic code generation.

## ✅ COMPLETED: Conversation-Based Refinement for Extraction - 2025-11-18 22:25

- **DONE: Implemented refinement logic for extraction retries** - Extraction now uses conversation-based refinement matching formalization pattern. **Implementation:** Added previous_attempt and previous_degradation parameters to LLMProvider.extract_to_smtlib protocol (`src/domain/protocols.py:56-77`). Updated AnthropicClient.extract_to_smtlib (`src/infrastructure/llm/client.py:162-248`) to build 3-message conversation on retry: initial prompt → previous SMT code → refinement feedback with degradation score and guidance. Updated extraction.py retry loop (`src/domain/steps/extraction.py:85-138`) to track and pass previous attempts. Temperature stays 0.0 for deterministic code generation. **Benefits:** Better convergence through iterative refinement vs simple regeneration, maintains context across retries, explicit feedback guides LLM to reduce information loss.

## ✅ COMPLETED: Use Exact 5-Phase SMT Prompt - 2025-11-18 22:12

- **DONE: Replaced EXTRACTION_PROMPT with exact 5-phase prompt** - The exact battle-tested 5-phase prompt from convert_to_smtlib function has been implemented verbatim in `src/infrastructure/llm/prompts.py:18-98`. The prompt enforces: Phase 1 (problem comprehension with data inventory), Phase 2 (domain modeling with ground truth vs unknowns, assert-and-test pattern for YES/NO), Phase 3 (logic selection decision tree), Phase 4 (SMT-LIB encoding with uninterpreted function linking constraints), Phase 5 (self-verification checklist). Only change made: replaced `{enhanced_text}` placeholder with `{formal_text}` to match our variable naming. Function `get_extraction_prompt()` updated to use new prompt (detail_level parameter deprecated but kept for API compatibility).